from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re

def initialize_driver():
    driver = webdriver.Chrome()
    return driver

def login_instagram(driver, username, password):
    login_url = 'https://www.instagram.com/accounts/login/'
    driver.get(login_url)
    
    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'username'))).send_keys(username)
    driver.find_element(By.NAME, 'password').send_keys(password)
    driver.find_element(By.XPATH, '//button[contains(@type, "submit")]').click()

    WebDriverWait(driver, 10).until(EC.url_changes(login_url))

def scroll_and_collect_post_urls(driver, profile_url):
    driver.get(profile_url)
    scroll_pause_time = 5
    last_height = driver.execute_script("return document.body.scrollHeight")

    post_urls = set()  # Use a set to avoid duplicate URLs

    while True:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(scroll_pause_time)
        
        post_links = driver.find_elements(By.XPATH, '//a[contains(@href, "/reel/")]')
        for link in post_links:
            post_urls.add(link.get_attribute('href'))

        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    return post_urls

def extract_post_details(post_url):
    response = requests.get(post_url)
    soup = BeautifulSoup(response.text, 'html.parser')


    try:
        caption_element = soup.find('meta', property='og:description')
        caption = caption_element['content'] if caption_element else 'No caption found'
    except Exception as e:
        caption = 'No caption found'
        print(f"Error retrieving caption: {e}")

    try:
        likes_element = soup.find('meta', property='og:description')
        likes_text = likes_element['content'] if likes_element else 'Likes not found'
        likes_match = re.search(r'(\d+,\d+|\d+)', likes_text.split(' Likes')[0])
        likes = likes_match.group(0) if likes_match else 'Likes not found'
    except Exception as e:
        likes = 'Likes not found'
        print(f"Error retrieving likes: {e}")


    try:
        comments_tag = soup.find('ul', {'class': 'Mr508'})
        comments = comments_tag.get_text(separator='\n') if comments_tag else 'Comments not found'
    except Exception as e:
        comments = 'Comments not found'
        print(f"Error retrieving comments: {e}")

  
    try:
        meta_tag = soup.find('meta', property='og:image')
        img_url = meta_tag['content'] if meta_tag else 'No image found'

    except Exception as e:
        img_url = 'No image found'
        print(f"Error retrieving image URL: {e}")


  
    hashtags = [part for part in caption.split() if part.startswith('#')]

    return {
        'URL': post_url,
        'Reel URL': img_url,
        'Caption': caption,
        'Likes': likes,
        'Comments': comments,
        'Hashtags': hashtags,
    }


def main():
    driver = initialize_driver()
    try:
        username = "chandrakantdeshpande57"
        password = "Cdd@5832"
        profile_url = 'https://www.instagram.com/brabus/' 

        login_instagram(driver, username, password)
        post_urls = scroll_and_collect_post_urls(driver, profile_url)

        posts_data = []
        for post_url in post_urls:
            print(f"Extracting details from: {post_url}")
            post_data = extract_post_details(post_url)
            posts_data.append(post_data)

        df = pd.DataFrame(posts_data)
        df.to_csv("millimidwood_instagram_reels_all.csv", index=False)

    finally:
        driver.quit()

if __name__ == "__main__":
    main()
